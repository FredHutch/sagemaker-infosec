"""\nIncident Response AI Agent\nLeverages Perplexity AI for intelligent incident analysis and response\n"""\n\nimport json\nimport logging\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nimport requests\n\nfrom .crowdstrike_client import CrowdStrikeClient\nfrom .microsoft_client import MicrosoftSecurityClient\nfrom .proofpoint_client import ProofpointClient\n\nlogger = logging.getLogger(__name__)\n\n\nclass IncidentResponseAgent:\n    """AI-powered incident response agent using Perplexity AI"""\n\n    def __init__(\n        self,\n        crowdstrike: CrowdStrikeClient,\n        microsoft: MicrosoftSecurityClient,\n        proofpoint: ProofpointClient,\n        perplexity_api_key: str\n    ):\n        """\n        Initialize incident response agent\n\n        Args:\n            crowdstrike: CrowdStrike client instance\n            microsoft: Microsoft Security client instance\n            proofpoint: Proofpoint client instance\n            perplexity_api_key: Perplexity API key for AI capabilities\n        """\n        self.crowdstrike = crowdstrike\n        self.microsoft = microsoft\n        self.proofpoint = proofpoint\n        self.perplexity_api_key = perplexity_api_key\n        self.api_url = "https://api.perplexity.ai/chat/completions"\n\n    def _call_perplexity_api(self, prompt: str, max_tokens: int = 4000) -> str:\n        """\n        Call Perplexity API with the given prompt\n        \n        Args:\n            prompt: The prompt to send to Perplexity\n            max_tokens: Maximum tokens in response\n            \n        Returns:\n            Response text from Perplexity\n        """\n        try:\n            response = requests.post(\n                self.api_url,\n                headers={\n                    "Authorization": f"Bearer {self.perplexity_api_key}",\n                    "Content-Type": "application/json"\n                },\n                json={\n                    "model": "sonar-pro",\n                    "messages": [{"role": "user", "content": prompt}],\n                    "max_tokens": max_tokens\n                },\n                timeout=60\n            )\n            response.raise_for_status()\n            return response.json()["choices"][0]["message"]["content"]\n        except requests.exceptions.RequestException as e:\n            logger.error(f"Error calling Perplexity API: {e}")\n            raise\n\n    def aggregate_incidents(\n        self,\n        cs_detections: Dict,\n        cs_incidents: Dict,\n        ms_alerts: Dict,\n        pp_events: Dict\n    ) -> List[Dict]:\n        """\n        Aggregate incidents from all security platforms\n\n        Returns:\n            List of normalized incident dictionaries\n        """\n        incidents = []\n\n        # Add CrowdStrike detections\n        for detection in cs_detections.get('detections', []):\n            incidents.append({\n                'id': detection.get('detection_id'),\n                'title': detection.get('behaviors', [{}])[0].get('scenario', 'Unknown'),\n                'description': detection.get('behaviors', [{}])[0].get('description', ''),\n                'severity': detection.get('max_severity_displayname', 'Unknown'),\n                'source': 'CrowdStrike',\n                'timestamp': detection.get('first_behavior'),\n                'raw_data': detection\n            })\n\n        # Add CrowdStrike incidents\n        for incident in cs_incidents.get('incidents', []):\n            incidents.append({\n                'id': incident.get('incident_id'),\n                'title': incident.get('name', 'Unnamed Incident'),\n                'description': incident.get('description', ''),\n                'severity': incident.get('state', 'Unknown'),\n                'source': 'CrowdStrike',\n                'timestamp': incident.get('start'),\n                'raw_data': incident\n            })\n\n        # Add Microsoft Defender alerts\n        for alert in ms_alerts.get('alerts', []):\n            incidents.append({\n                'id': alert.get('id'),\n                'title': alert.get('title', 'Unknown Alert'),\n                'description': alert.get('description', ''),\n                'severity': alert.get('severity', 'Unknown'),\n                'source': 'Microsoft Defender',\n                'timestamp': alert.get('created_datetime'),\n                'raw_data': alert\n            })\n\n        # Add Proofpoint events (high-value threats only)\n        for msg in pp_events.get('messages_blocked', []):\n            if msg.get('threatType') in ['url', 'attachment']:\n                incidents.append({\n                    'id': msg.get('GUID'),\n                    'title': f"Malicious Email Blocked: {msg.get('threatType')}",\n                    'description': msg.get('subject', ''),\n                    'severity': 'High',\n                    'source': 'Proofpoint',\n                    'timestamp': msg.get('messageTime'),\n                    'raw_data': msg\n                })\n\n        return incidents\n\n    async def analyze_incidents(self, incidents: List[Dict]) -> Dict:\n        """\n        Use AI to analyze and prioritize incidents\n\n        Args:\n            incidents: List of incident dictionaries\n\n        Returns:\n            Dictionary with prioritized incidents and analysis\n        """\n        # Prepare data for AI analysis\n        incident_summary = self._prepare_incident_summary(incidents)\n\n        # Create AI prompt\n        prompt = f"""You are a security analyst reviewing recent security incidents. Analyze the following incidents and:\n\n1. Prioritize them as High, Medium, or Low based on severity, potential impact, and risk\n2. Identify potential attack campaigns or related incidents\n3. Provide AI risk scores (0-100) for each high-priority incident\n4. Recommend specific actions for each high-priority incident\n5. Explain your reasoning\n\nIncidents to analyze:\n{json.dumps(incident_summary, indent=2)}\n\nProvide your analysis in JSON format with the following structure:\n{{\n    "high_priority": [\n        {{\n            "id": "incident_id",\n            "title": "incident_title",\n            "source": "source_platform",\n            "severity": "severity",\n            "ai_risk_score": 85,\n            "recommended_actions": ["action1", "action2"],\n            "ai_reasoning": "explanation"\n        }}\n    ],\n    "medium_priority": [...],\n    "low_priority": [...],\n    "campaigns": [\n        {{\n            "name": "Campaign name",\n            "related_incidents": ["id1", "id2"],\n            "description": "Campaign description"\n        }}\n    ]\n}}"""\n\n        try:\n            # Call Perplexity API\n            analysis_text = self._call_perplexity_api(prompt, max_tokens=4000)\n            \n            # Extract JSON from response\n            json_start = analysis_text.find('{')\n            json_end = analysis_text.rfind('}') + 1\n            analysis = json.loads(analysis_text[json_start:json_end])\n\n            return analysis\n\n        except Exception as e:\n            logger.error(f"Error in AI analysis: {e}")\n            # Return basic prioritization if AI fails\n            return self._basic_prioritization(incidents)\n\n    def _prepare_incident_summary(self, incidents: List[Dict]) -> List[Dict]:\n        """Prepare incident data for AI analysis"""\n        summary = []\n        for inc in incidents[:50]:  # Limit to avoid token limits\n            summary.append({\n                'id': inc.get('id'),\n                'title': inc.get('title'),\n                'description': inc.get('description', '')[:200],  # Truncate long descriptions\n                'severity': inc.get('severity'),\n                'source': inc.get('source'),\n                'timestamp': inc.get('timestamp')\n            })\n        return summary\n\n    def _basic_prioritization(self, incidents: List[Dict]) -> Dict:\n        """Basic prioritization if AI is unavailable"""\n        high_severity = ['Critical', 'High', 'critical', 'high']\n        medium_severity = ['Medium', 'medium']\n\n        return {\n            'high_priority': [inc for inc in incidents if inc.get('severity') in high_severity],\n            'medium_priority': [inc for inc in incidents if inc.get('severity') in medium_severity],\n            'low_priority': [inc for inc in incidents if inc.get('severity') not in high_severity + medium_severity],\n            'campaigns': []\n        }\n\n    async def investigate_incident(\n        self,\n        incident: Dict,\n        include_timeline: bool = True,\n        include_related_events: bool = True,\n        include_threat_intel: bool = True\n    ) -> Dict:\n        """\n        Perform deep investigation of an incident\n\n        Args:\n            incident: Incident dictionary\n            include_timeline: Build event timeline\n            include_related_events: Find related events\n            include_threat_intel: Lookup threat intelligence\n\n        Returns:\n            Investigation results dictionary\n        """\n        investigation = {\n            'incident_id': incident.get('id'),\n            'timeline': [],\n            'related_events': [],\n            'threat_intel': {},\n            'affected_assets': {},\n            'ai_summary': ''\n        }\n\n        # Build timeline\n        if include_timeline:\n            investigation['timeline'] = await self._build_timeline(incident)\n\n        # Find related events\n        if include_related_events:\n            investigation['related_events'] = await self._find_related_events(incident)\n\n        # Get threat intelligence\n        if include_threat_intel:\n            investigation['threat_intel'] = await self._get_threat_intelligence(incident)\n\n        # Get affected assets\n        investigation['affected_assets'] = self._extract_affected_assets(incident)\n\n        # Generate AI summary\n        investigation['ai_summary'] = await self._generate_investigation_summary(investigation)\n\n        return investigation\n\n    async def _build_timeline(self, incident: Dict) -> List[Dict]:\n        """Build event timeline for incident"""\n        timeline = []\n        # Add initial incident\n        timeline.append({\n            'timestamp': incident.get('timestamp'),\n            'description': f"Incident detected: {incident.get('title')}",\n            'source': incident.get('source'),\n            'indicators': []\n        })\n        return timeline\n\n    async def _find_related_events(self, incident: Dict) -> List[Dict]:\n        """Find events related to the incident"""\n        related = []\n        # Implementation would query all sources for related events\n        return related\n\n    async def _get_threat_intelligence(self, incident: Dict) -> Dict:\n        """Get threat intelligence for incident indicators"""\n        threat_intel = {\n            'actor': 'Unknown',\n            'ttps': [],\n            'malware_family': 'Unknown'\n        }\n        # Implementation would query threat intel sources\n        return threat_intel\n\n    def _extract_affected_assets(self, incident: Dict) -> Dict:\n        """Extract affected hosts and users from incident"""\n        return {\n            'hosts': [],\n            'users': []\n        }\n\n    async def _generate_investigation_summary(self, investigation: Dict) -> str:\n        """Generate AI summary of investigation"""\n        prompt = f"""Summarize this security incident investigation in 2-3 paragraphs:\n\n{json.dumps(investigation, indent=2, default=str)}\n\nFocus on:\n1. What happened\n2. Potential impact\n3. Key findings\n4. Recommended next steps"""\n\n        try:\n            return self._call_perplexity_api(prompt, max_tokens=1000)\n        except Exception as e:\n            logger.error(f"Error generating summary: {e}")\n            return "Investigation summary unavailable."\n\n    def generate_response_plan(\n        self,\n        incident: Dict,\n        investigation: Dict,\n        playbook: Dict\n    ) -> Dict:\n        """Generate automated response plan"""\n        return {\n            'containment': [\n                {\n                    'description': 'Isolate affected hosts',\n                    'impact': 'High - will disconnect hosts from network',\n                    'risk_level': 'Medium',\n                    'can_automate': False\n                }\n            ],\n            'eradication': [],\n            'recovery': []\n        }\n\n    async def execute_response_actions(\n        self,\n        actions: List[Dict],\n        auto_approve_safe_actions: bool = False\n    ) -> List[Dict]:\n        """Execute response actions"""\n        results = []\n        for action in actions:\n            if action.get('can_automate') or auto_approve_safe_actions:\n                results.append({\n                    'action': action['description'],\n                    'success': True,\n                    'message': 'Action completed successfully (simulated)'\n                })\n            else:\n                results.append({\n                    'action': action['description'],\n                    'success': False,\n                    'message': 'Action requires manual approval'\n                })\n        return results\n\n    def generate_incident_report(\n        self,\n        incident: Dict,\n        investigation: Dict,\n        response_actions: List[Dict],\n        include_executive_summary: bool = True,\n        include_technical_details: bool = True,\n        include_recommendations: bool = True\n    ) -> Dict:\n        """Generate comprehensive incident report"""\n        report_content = f"""# Incident Response Report\n\n## Incident Information\n- **ID**: {incident.get('id')}\n- **Title**: {incident.get('title')}\n- **Severity**: {incident.get('severity')}\n- **Source**: {incident.get('source')}\n- **Timestamp**: {incident.get('timestamp')}\n\n## Investigation Summary\n{investigation.get('ai_summary', 'No summary available')}\n\n## Response Actions Taken\n"""\n        for action in response_actions:\n            status = "✓" if action.get('success') else "✗"\n            report_content += f"- {status} {action.get('action')}: {action.get('message')}\\n"\n\n        report_content += "\\n## Recommendations\\n"\n        report_content += "- Review and update security policies\\n"\n        report_content += "- Conduct security awareness training\\n"\n        report_content += "- Monitor for similar indicators\\n"\n\n        return {\n            'incident_id': incident.get('id'),\n            'content': report_content\n        }\n