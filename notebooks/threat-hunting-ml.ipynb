{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Threat Hunting with Machine Learning\n",
    "\n",
    "This notebook provides advanced threat hunting capabilities using:\n",
    "- **Machine Learning** for anomaly detection and behavior analysis\n",
    "- **Claude AI** for hypothesis generation and pattern analysis\n",
    "- **Multi-source data correlation** from security tools\n",
    "- **MITRE ATT&CK framework** mapping\n",
    "- **Automated hunting workflows**\n",
    "\n",
    "## Hunting Techniques\n",
    "1. Behavioral anomaly detection using ML\n",
    "2. Network traffic pattern analysis\n",
    "3. User and entity behavior analytics (UEBA)\n",
    "4. Threat intelligence correlation\n",
    "5. Lateral movement detection\n",
    "6. Data exfiltration detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import networkx as nx\n",
    "from anthropic import Anthropic\n",
    "import boto3\n",
    "\n",
    "# Add local modules to path\n",
    "sys.path.append('/home/sagemaker-user/lib')\n",
    "\n",
    "# Import security tool integrations\n",
    "from security_integrations.crowdstrike_client import CrowdStrikeClient\n",
    "from security_integrations.microsoft_client import MicrosoftSecurityClient\n",
    "from security_integrations.proofpoint_client import ProofpointClient\n",
    "from security_integrations.threat_hunting import ThreatHuntingEngine\n",
    "\n",
    "# Configure visualization\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Security Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize security tool clients\n",
    "crowdstrike = CrowdStrikeClient()\n",
    "microsoft = MicrosoftSecurityClient()\n",
    "proofpoint = ProofpointClient()\n",
    "\n",
    "# Initialize threat hunting engine\n",
    "hunting_engine = ThreatHuntingEngine(\n",
    "    crowdstrike=crowdstrike,\n",
    "    microsoft=microsoft,\n",
    "    proofpoint=proofpoint\n",
    ")\n",
    "\n",
    "# Set hunting time window (last 7 days)\n",
    "hunt_days = 7\n",
    "start_time = (datetime.utcnow() - timedelta(days=hunt_days)).isoformat() + 'Z'\n",
    "\n",
    "print(f\"‚úì Threat hunting engine initialized\")\n",
    "print(f\"Hunting window: Last {hunt_days} days (from {start_time})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection and Aggregation\n",
    "\n",
    "Collect security data from all sources for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Collecting security data from all sources...\\n\")\n",
    "\n",
    "# Collect endpoint data from CrowdStrike\n",
    "print(\"Collecting CrowdStrike data...\")\n",
    "cs_data = await hunting_engine.collect_crowdstrike_data(\n",
    "    start_time=start_time,\n",
    "    include_detections=True,\n",
    "    include_host_activity=True,\n",
    "    include_network_activity=True\n",
    ")\n",
    "print(f\"  - Detections: {len(cs_data['detections'])}\")\n",
    "print(f\"  - Hosts monitored: {len(cs_data['hosts'])}\")\n",
    "print(f\"  - Network events: {len(cs_data['network_events'])}\")\n",
    "\n",
    "# Collect identity data from Microsoft\n",
    "print(\"\\nCollecting Microsoft data...\")\n",
    "ms_data = await hunting_engine.collect_microsoft_data(\n",
    "    start_time=start_time,\n",
    "    include_sign_ins=True,\n",
    "    include_alerts=True,\n",
    "    include_risky_users=True\n",
    ")\n",
    "print(f\"  - Sign-in events: {len(ms_data['sign_ins'])}\")\n",
    "print(f\"  - Alerts: {len(ms_data['alerts'])}\")\n",
    "print(f\"  - Risky users: {len(ms_data['risky_users'])}\")\n",
    "\n",
    "# Collect email threat data from Proofpoint\n",
    "print(\"\\nCollecting Proofpoint data...\")\n",
    "pp_data = await hunting_engine.collect_proofpoint_data(\n",
    "    interval=f\"P{hunt_days}D\"\n",
    ")\n",
    "print(f\"  - Threat events: {pp_data['total_events']}\")\n",
    "print(f\"  - Top clickers: {len(pp_data['top_clickers'])}\")\n",
    "print(f\"  - VAP users: {len(pp_data['vap_users'])}\")\n",
    "\n",
    "# Aggregate all data\n",
    "aggregated_data = hunting_engine.aggregate_data(cs_data, ms_data, pp_data)\n",
    "\n",
    "print(f\"\\n‚úì Data collection complete\")\n",
    "print(f\"Total events aggregated: {len(aggregated_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Behavioral Anomaly Detection\n",
    "\n",
    "Use machine learning to detect anomalous behavior patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Running ML-based anomaly detection...\\n\")\n",
    "\n",
    "# Prepare features for ML\n",
    "features_df = hunting_engine.prepare_ml_features(aggregated_data)\n",
    "\n",
    "print(f\"Feature matrix shape: {features_df.shape}\")\n",
    "print(f\"Features: {', '.join(features_df.columns)}\\n\")\n",
    "\n",
    "# User Behavior Anomaly Detection\n",
    "print(\"Detecting user behavior anomalies...\")\n",
    "user_features = features_df[[\n",
    "    'login_hour', 'login_country_diversity', 'failed_login_count',\n",
    "    'successful_login_count', 'ip_diversity', 'application_diversity'\n",
    "]].fillna(0)\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.1,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "user_anomalies = iso_forest.fit_predict(user_features)\n",
    "\n",
    "# Get anomalous users\n",
    "features_df['user_anomaly_score'] = iso_forest.score_samples(user_features)\n",
    "anomalous_users = features_df[user_anomalies == -1].sort_values('user_anomaly_score')\n",
    "\n",
    "print(f\"Anomalous users detected: {len(anomalous_users)}\\n\")\n",
    "\n",
    "# Display top anomalies\n",
    "print(\"Top 10 Anomalous User Behaviors:\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in anomalous_users.head(10).iterrows():\n",
    "    print(f\"\\nUser: {row.get('user_principal_name', 'Unknown')}\")\n",
    "    print(f\"  Anomaly Score: {row['user_anomaly_score']:.4f}\")\n",
    "    print(f\"  Failed Logins: {row['failed_login_count']:.0f}\")\n",
    "    print(f\"  Country Diversity: {row['login_country_diversity']:.0f}\")\n",
    "    print(f\"  IP Diversity: {row['ip_diversity']:.0f}\")\n",
    "    print(f\"  Unusual Login Hours: {row['login_hour']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Network Traffic Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåê Analyzing network traffic patterns...\\n\")\n",
    "\n",
    "# Analyze network connections\n",
    "network_data = cs_data.get('network_events', [])\n",
    "\n",
    "if network_data:\n",
    "    network_df = pd.DataFrame(network_data)\n",
    "    \n",
    "    # Detect beaconing behavior (C2 communication)\n",
    "    print(\"Detecting beaconing patterns...\")\n",
    "    beaconing_results = hunting_engine.detect_beaconing(\n",
    "        network_df,\n",
    "        time_threshold=60,  # seconds\n",
    "        count_threshold=10\n",
    "    )\n",
    "    \n",
    "    if beaconing_results:\n",
    "        print(f\"\\n‚ö†Ô∏è Potential C2 beaconing detected: {len(beaconing_results)} patterns\")\n",
    "        for beacon in beaconing_results[:5]:\n",
    "            print(f\"\\n  Host: {beacon['host']}\")\n",
    "            print(f\"  Destination: {beacon['destination_ip']}:{beacon['destination_port']}\")\n",
    "            print(f\"  Connection frequency: Every {beacon['avg_interval']:.1f} seconds\")\n",
    "            print(f\"  Connection count: {beacon['connection_count']}\")\n",
    "    else:\n",
    "        print(\"No beaconing patterns detected\")\n",
    "    \n",
    "    # Detect data exfiltration\n",
    "    print(\"\\nDetecting potential data exfiltration...\")\n",
    "    exfiltration_results = hunting_engine.detect_data_exfiltration(\n",
    "        network_df,\n",
    "        byte_threshold=10 * 1024 * 1024  # 10 MB\n",
    "    )\n",
    "    \n",
    "    if exfiltration_results:\n",
    "        print(f\"\\n‚ö†Ô∏è Potential data exfiltration detected: {len(exfiltration_results)} events\")\n",
    "        for exfil in exfiltration_results[:5]:\n",
    "            print(f\"\\n  Host: {exfil['host']}\")\n",
    "            print(f\"  Destination: {exfil['destination_ip']}\")\n",
    "            print(f\"  Bytes transferred: {exfil['bytes_out'] / (1024*1024):.2f} MB\")\n",
    "            print(f\"  Timestamp: {exfil['timestamp']}\")\n",
    "    else:\n",
    "        print(\"No suspicious data exfiltration detected\")\n",
    "else:\n",
    "    print(\"No network data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lateral Movement Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÄ Detecting lateral movement...\\n\")\n",
    "\n",
    "# Build network graph of host-to-host communications\n",
    "G = hunting_engine.build_network_graph(cs_data.get('network_events', []))\n",
    "\n",
    "print(f\"Network graph: {G.number_of_nodes()} hosts, {G.number_of_edges()} connections\")\n",
    "\n",
    "# Detect lateral movement patterns\n",
    "lateral_movement = hunting_engine.detect_lateral_movement(\n",
    "    G,\n",
    "    min_connections=3,\n",
    "    time_window_hours=1\n",
    ")\n",
    "\n",
    "if lateral_movement:\n",
    "    print(f\"\\n‚ö†Ô∏è Potential lateral movement detected: {len(lateral_movement)} patterns\\n\")\n",
    "    \n",
    "    for i, pattern in enumerate(lateral_movement[:5], 1):\n",
    "        print(f\"{i}. Source: {pattern['source_host']}\")\n",
    "        print(f\"   Targets: {', '.join(pattern['target_hosts'][:5])}\")\n",
    "        if len(pattern['target_hosts']) > 5:\n",
    "            print(f\"   ... and {len(pattern['target_hosts']) - 5} more\")\n",
    "        print(f\"   Protocol: {pattern['protocol']}\")\n",
    "        print(f\"   Risk Score: {pattern['risk_score']}/10\")\n",
    "        print()\n",
    "    \n",
    "    # Visualize lateral movement\n",
    "    if lateral_movement:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Create subgraph for top lateral movement pattern\n",
    "        pattern = lateral_movement[0]\n",
    "        nodes = [pattern['source_host']] + pattern['target_hosts'][:10]\n",
    "        subgraph = G.subgraph(nodes)\n",
    "        \n",
    "        # Draw network graph\n",
    "        pos = nx.spring_layout(subgraph)\n",
    "        nx.draw_networkx_nodes(subgraph, pos, node_color='lightblue', \n",
    "                               node_size=500, ax=ax)\n",
    "        nx.draw_networkx_nodes(subgraph, pos, nodelist=[pattern['source_host']],\n",
    "                               node_color='red', node_size=700, ax=ax)\n",
    "        nx.draw_networkx_edges(subgraph, pos, edge_color='gray', \n",
    "                               arrows=True, ax=ax)\n",
    "        nx.draw_networkx_labels(subgraph, pos, font_size=8, ax=ax)\n",
    "        \n",
    "        ax.set_title('Lateral Movement Pattern Visualization')\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No lateral movement patterns detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AI-Powered Hypothesis Generation\n",
    "\n",
    "Use Claude AI to generate threat hunting hypotheses based on findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Generating AI-powered hunting hypotheses...\\n\")\n",
    "\n",
    "# Compile findings for AI analysis\n",
    "findings = {\n",
    "    'anomalous_users': anomalous_users.head(10).to_dict('records'),\n",
    "    'beaconing': beaconing_results if network_data else [],\n",
    "    'lateral_movement': lateral_movement if lateral_movement else [],\n",
    "    'risky_users': ms_data.get('risky_users', []),\n",
    "    'top_clickers': pp_data.get('top_clickers', []),\n",
    "}\n",
    "\n",
    "# Generate hypotheses with Claude\n",
    "hypotheses = await hunting_engine.generate_hunting_hypotheses(findings)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI-GENERATED THREAT HUNTING HYPOTHESES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, hypothesis in enumerate(hypotheses, 1):\n",
    "    print(f\"\\n{i}. {hypothesis['title']}\")\n",
    "    print(f\"   Priority: {hypothesis['priority']}\")\n",
    "    print(f\"   MITRE ATT&CK: {', '.join(hypothesis['mitre_tactics'])}\")\n",
    "    print(f\"   \\n   Description: {hypothesis['description']}\")\n",
    "    print(f\"   \\n   Hunting Approach:\")\n",
    "    for step in hypothesis['hunting_steps']:\n",
    "        print(f\"     ‚Ä¢ {step}\")\n",
    "    print(f\"   \\n   Expected Indicators:\")\n",
    "    for indicator in hypothesis['expected_indicators']:\n",
    "        print(f\"     ‚Ä¢ {indicator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Execute Hypothesis-Driven Hunt\n",
    "\n",
    "Execute a specific hunting hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hypothesis to investigate (user can change this)\n",
    "hypothesis_index = 0  # First hypothesis\n",
    "\n",
    "if hypotheses:\n",
    "    selected_hypothesis = hypotheses[hypothesis_index]\n",
    "    \n",
    "    print(f\"üéØ Executing hunt for: {selected_hypothesis['title']}\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Execute automated hunt\n",
    "    hunt_results = await hunting_engine.execute_hunt(\n",
    "        hypothesis=selected_hypothesis,\n",
    "        data_sources={\n",
    "            'crowdstrike': cs_data,\n",
    "            'microsoft': ms_data,\n",
    "            'proofpoint': pp_data\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nHunt Status: {hunt_results['status']}\")\n",
    "    print(f\"Evidence Found: {len(hunt_results['evidence'])} items\\n\")\n",
    "    \n",
    "    if hunt_results['evidence']:\n",
    "        print(\"EVIDENCE DISCOVERED:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, evidence in enumerate(hunt_results['evidence'][:10], 1):\n",
    "            print(f\"\\n{i}. {evidence['description']}\")\n",
    "            print(f\"   Source: {evidence['source']}\")\n",
    "            print(f\"   Timestamp: {evidence['timestamp']}\")\n",
    "            print(f\"   Confidence: {evidence['confidence']}%\")\n",
    "            if evidence.get('indicators'):\n",
    "                print(f\"   Indicators: {', '.join(evidence['indicators'])}\")\n",
    "        \n",
    "        # AI summary of findings\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"AI ANALYSIS OF FINDINGS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(hunt_results['ai_summary'])\n",
    "        \n",
    "        # Recommended actions\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"RECOMMENDED ACTIONS\")\n",
    "        print(\"=\" * 80)\n",
    "        for action in hunt_results['recommended_actions']:\n",
    "            print(f\"‚Ä¢ {action}\")\n",
    "    else:\n",
    "        print(\"No evidence found for this hypothesis.\")\n",
    "else:\n",
    "    print(\"No hypotheses available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MITRE ATT&CK Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üó∫Ô∏è Mapping findings to MITRE ATT&CK Framework...\\n\")\n",
    "\n",
    "# Map all findings to MITRE ATT&CK\n",
    "mitre_mapping = hunting_engine.map_to_mitre_attack(\n",
    "    findings={\n",
    "        'anomalies': anomalous_users.to_dict('records'),\n",
    "        'lateral_movement': lateral_movement if lateral_movement else [],\n",
    "        'hunt_results': hunt_results if hypotheses else {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display MITRE ATT&CK coverage\n",
    "print(\"MITRE ATT&CK Techniques Observed:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for tactic, techniques in mitre_mapping.items():\n",
    "    print(f\"\\n{tactic.upper()}:\")\n",
    "    for technique in techniques:\n",
    "        print(f\"  ‚Ä¢ {technique['id']}: {technique['name']}\")\n",
    "        print(f\"    Evidence count: {technique['evidence_count']}\")\n",
    "        print(f\"    Confidence: {technique['confidence']}%\")\n",
    "\n",
    "# Visualize MITRE ATT&CK heatmap\n",
    "mitre_df = hunting_engine.create_mitre_heatmap_data(mitre_mapping)\n",
    "\n",
    "if not mitre_df.empty:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(mitre_df, annot=True, fmt='d', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Evidence Count'})\n",
    "    plt.title('MITRE ATT&CK Technique Coverage')\n",
    "    plt.xlabel('Techniques')\n",
    "    plt.ylabel('Tactics')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Threat Hunting Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù Generating threat hunting report...\\n\")\n",
    "\n",
    "# Generate comprehensive report\n",
    "report = hunting_engine.generate_hunting_report(\n",
    "    hunt_period=f\"Last {hunt_days} days\",\n",
    "    anomalies=anomalous_users,\n",
    "    network_analysis={\n",
    "        'beaconing': beaconing_results if network_data else [],\n",
    "        'lateral_movement': lateral_movement if lateral_movement else []\n",
    "    },\n",
    "    hypotheses=hypotheses,\n",
    "    hunt_results=hunt_results if hypotheses else {},\n",
    "    mitre_mapping=mitre_mapping\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"THREAT HUNTING REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(report['content'])\n",
    "\n",
    "# Save report\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = os.getenv('SAGEMAKER_NOTEBOOKS_BUCKET', 'sagemaker-infosec-notebooks')\n",
    "report_key = f\"threat-hunting-reports/{datetime.utcnow().strftime('%Y-%m-%d')}.md\"\n",
    "\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=report_key,\n",
    "    Body=report['content'],\n",
    "    ContentType='text/markdown'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Report saved to s3://{bucket_name}/{report_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save ML Models for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save trained models\n",
    "print(\"üíæ Saving ML models...\\n\")\n",
    "\n",
    "model_dir = '/tmp/threat-hunting-models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save Isolation Forest model\n",
    "joblib.dump(iso_forest, f'{model_dir}/user_anomaly_detector.pkl')\n",
    "print(\"‚úì Saved user anomaly detection model\")\n",
    "\n",
    "# Upload to S3\n",
    "s3_client.upload_file(\n",
    "    f'{model_dir}/user_anomaly_detector.pkl',\n",
    "    bucket_name.replace('notebooks', 'models'),\n",
    "    'threat-hunting/user_anomaly_detector.pkl'\n",
    ")\n",
    "\n",
    "print(\"‚úì Models uploaded to S3\")\n",
    "print(\"\\nModels can be loaded in future sessions for real-time threat detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
